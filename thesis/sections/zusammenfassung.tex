%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.1, 2014-11-21

\chapter{Zusammenfassung und Ausblick}
\label{ch:zusammenfassung}

In dieser Bachelorarbeit wurde eine Datenflussdokumentation auf Architekturebene vorgestellt. Mit dieser Datenflussdokumentation ist es möglich Modelle des \gls{pcm} um Daten und Datenflüsse zu erweitern. Die Elemente, mit denen das möglich ist, sind in \autoref{ch:modellierung} beschrieben. In \autoref{ch:validierung} wurde dann mithilfe eines Fallbeispiels gezeigt, dass mit der Modellierung Daten und Datenflüsse modelliert werden können. Dabei ist eine Modellierung von Daten und Datenflüssen, ausgehend vom Benutzer des Systems, zu den Komponenten und innerhalb der Komponenten möglich. Außerdem wurde gezeigt, dass die Modellierung in Datenflussanalysen verwendet werden kann. Dazu wurden die Datenflüsse innerhalb des Modells analysiert und transformiert. Das transformierte Modell wurde verwendet um die Eingabe und Ausgabe des Fallbeispiels zu spezifizieren. Anschließend wurde versucht mithilfe einer Vertraulichkeitsanalyse nach Kramer et. al. \cite{Kramera} diese Modellierung zu überprüfen. Leider konnte diese, aufgrund eines Defekts, nicht vollständig ausgeführt werden. Stattdessen wurden das Vertraulichkeitsmodell und das transformierte Modell verglichen. Die Unterschiede wurden diskutiert und zu dem Ergebnis geführt, dass die Modellierung dieser Bachelorarbeit durchaus für Datenflussanalysen geeignet ist. \par 
Die Datenflussdokumentation, die in dieser Bachelorarbeit entstanden ist, dient dabei die einzelnen Rollen und die dazugehörigen Modelle, des \gls{pcm}, zu erweitern. Sie ermöglicht dem Komponentenentwickler das Verhalten innerhalb von Komponenten um einen Datenfluss zu erweitern. Somit wird das Komponenten-Reposiory-Modell erweitert. Auch dem Domänenexperten wird es ermöglicht Datenflüsse zu modellieren. Die Datenflüsse gehen vom Benutzer aus und erweitern das Nutzungsmodell. Schließlich wird dem Software-Verteilungsexperten ermöglicht eine Hardware-Spezifikation im Ressourcen-Umgebungs-Modell durchzuführen. \par
Für zukünftige Arbeiten könnte die Modellierung dieser Bachelorarbeit mit weiteren Fallbeispielen validiert werden. Indem weitere Fallbeispiele erstellt oder existierende aus der Literatur mit Datenflüssen erweitert werden, könnte die Modellierung genauer validiert werden. Als Beispiel würde sich z.B. das zweite Fallbeispiel aus der Arbeit von Kramer et. al. \cite{Kramera} eignen, da dieses bereits über modellierte PCM-Modelle verfügt. Außerdem könnten weitere Datenflussanalysen betrachtet werden. Dabei könnten andere Sicherheitseigenschaften überprüft werden. Die Datenflussanalyse aus der Arbeit \textbf{UMLsec} \cite{Jurjens2005} könnte sich dazu eignen. Dafür müsste die dortige Modellierung und Analyse betrachtet werden und im Anschluss eine Transformation geschrieben werden, die ein Modell dieser Bachelorarbeit in ein \textbf{UMLsec}-Modell transformiert. Dazu könnten die Fallbeispiele von \textbf{UMLsec} mithilfe des \gls{pcm} nachmodelliert, mit Daten und Datenflüssen erweitert und die jeweiligen Ergebnisse verglichen werden. Um die Modellierung besser in Palladio-Workbench zu integrieren, könnte ein graphischer Editor erstellt werden, mit dem Daten und Datenflüsse erstellt werden können. Damit könnte die Akzeptanz bei den Architekten geprüft werden. Die Masterarbeit \textbf{Flexible Graphical Editors for Extensible Modular Meta Models} von Michael Junker, setzt sich mit dem Thema auseinander, wie sich erweiterbare Meta-Modelle auf flexible graphische Editoren auswirken. Dabei wurde auch die Erweiterung dieser Bachelorarbeit betrachtet. Außerdem wird in einer weiteren Masterarbeit von Philipp Weimann diese Bacheorarbeit auch betrachtet. In der Masterarbeit werden Applikationen untersucht, die verteilt in der Cloud liegen. Auslagerungen sollen dabei automatisch erkannt werden und bei Verstoß gegen vorgegebene Richtlinien eine alternative Verteilung des Systems ermittelt und angewendet werden.


